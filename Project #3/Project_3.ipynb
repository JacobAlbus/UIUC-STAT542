{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c95c30-a52f-4eb9-8f99-728df09c929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,Ridge\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643c0d20-4336-4aaa-99d3-c866235a0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/split_1/train.tsv\", sep='\\t', header=0, dtype=str)\n",
    "train['review'] = train['review'].str.replace('<.*?>', ' ', regex=True)\n",
    "y_train = train[\"sentiment\"].astype(int)\n",
    "\n",
    "test = pd.read_csv(\"data/split_1/test.tsv\", sep='\\t', header=0, dtype=str)\n",
    "test['review'] = test['review'].str.replace('<.*?>', ' ', regex=True)\n",
    "\n",
    "y_test = pd.read_csv(\"data/split_1/test_y.tsv\", sep='\\t', header=0, dtype=int)\n",
    "y_test = y_test[\"sentiment\"].astype(int)\n",
    "\n",
    "combined_reviews = pd.concat([train['review'], test['review']], ignore_index=True)\n",
    "combined_y = pd.concat([y_train, y_test], ignore_index =True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1550e510-0749-4967-bb97-f330e3616049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below stopwords from nltk stopwords\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    preprocessor=lambda x: x.lower(),  # Convert to lowercase\n",
    "    stop_words=stop_words,             # Remove stop words\n",
    "    ngram_range=(1, 4),               # Use 1- to 4-grams\n",
    "    min_df=0.001,                        # Minimum term frequency\n",
    "    max_df=0.5,                       # Maximum document frequency\n",
    "    token_pattern=r\"\\b[\\w+\\|']+\\b\" # Use word tokenizer: See Ethan's comment below\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dca1256-68ee-4255-a69f-117843135383",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train = vectorizer.fit_transform(combined_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2058945-2012-4d4a-8ef1-207bcd04c4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.25, max_iter=300, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.25, max_iter=300, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.25, max_iter=300, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.25,  max_iter=300)\n",
    "lasso.fit(dtm_train, combined_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e572e6-bc6b-44af-a66a-8a89434328fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0 10' '00' ... 'zombies' 'zone' 'zoom']\n",
      "['3 10' '4 10' '8 10' '1 10' '2 10' 'stinker' '10 10' 'forgettable'\n",
      " 'mst3k' 'waste' 'well worth' 'refreshing' 'disappointment'\n",
      " 'highly recommend' 'give 4' 'lifeless' '9 10' 'yawn' 'one worst' 'poorly'\n",
      " 'olds' 'definitely worth' 'worst' 'laughable' \"can't wait\"\n",
      " 'highly recommended' 'awful' 'mildly' 'tedious' 'must see'\n",
      " 'uninteresting' 'dreadful' \"that's point\" 'grade b' 'unfunny'\n",
      " 'entertains' 'wonderfully' \"i'm afraid\" 'lacks' 'amateurish'\n",
      " 'unremarkable' 'wasting' 'fails' 'lousy' 'first rate' 'disappointing'\n",
      " 'tiresome' 'fast forward' 'excellently' 'funniest' 'redeeming' 'dull'\n",
      " 'uninspired' 'subtle' 'alright' 'pretentious' 'superb' 'mediocre'\n",
      " 'miscast' 'credibility' 'ladder' 'loved movie' 'embarrassed' 'bland'\n",
      " 'avoid' 'lame' 'appalling' 'horrible' 'hype' 'wanted like' 'made sense'\n",
      " 'one best' 'excellent' 'gem' 'hilarious' 'definitely recommend'\n",
      " 'one better' 'mess' 'incoherent' 'terrible' 'worst movie' 'rainy'\n",
      " 'unwatchable' 'boring' 'brilliantly' 'pathetic' 'british comedy'\n",
      " 'stock footage' 'amazing' 'hepburn' 'love movie' 'obnoxious' 'sucks'\n",
      " 'minute movie' 'eerie' 'time period' 'boll' 'total lack' 'pointless']\n"
     ]
    }
   ],
   "source": [
    "coef = lasso.coef_.ravel()\n",
    "selected_features = np.where(coef != 0)[0]\n",
    "sorted_features = np.argsort(np.abs(coef[selected_features]))[::-1]\n",
    "selected_features = selected_features[sorted_features[:1000]]\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "print(feature_names)\n",
    "selected_words = feature_names[selected_features]\n",
    "print(selected_words[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f516608a-29dd-40d6-b80c-ac3802fadbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=272)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=272)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=272)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myvocab = selected_words \n",
    "\n",
    "\n",
    "vocabvectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),  # Adjust ngram_range to 4 for testing\n",
    "    vocabulary=myvocab  \n",
    ")\n",
    "\n",
    "dtm_train = vocabvectorizer.transform(train['review'])\n",
    "\n",
    "y_train = train['sentiment'].astype(int)\n",
    "\n",
    "# Applying Ridge Regression on the transformed data\n",
    "ridge = Ridge(alpha=272)  # Alpha can be adjusted based on model tuning\n",
    "ridge.fit(dtm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c7ab67-4ac5-4e5c-8402-8b87df1299c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/split_1/test.tsv\", sep='\\t', header=0, dtype=str)\n",
    "test['review'] = test['review'].str.replace('<.*?>', ' ', regex=True)\n",
    "\n",
    "y_test = pd.read_csv(\"data/split_1/test_y.tsv\", sep='\\t', header=0, dtype=int)\n",
    "y_test = y_test[\"sentiment\"].astype(int)\n",
    "dtm_test = vocabvectorizer.transform(test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cad75e2-5da4-4eff-a2d6-d7b06526abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9495134796500907\n"
     ]
    }
   ],
   "source": [
    "y_pred = ridge.predict(dtm_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43c6d759-2826-4d13-a03d-0120192835c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69392785, 0.62829483, 0.54021108, ..., 0.43282653, 0.65947415,\n",
       "       0.66900518])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = np.where(y_pred2 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "895d2bb9-a3a4-437b-8c38-23f802cffa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for split5: 0.8734971796215898\n"
     ]
    }
   ],
   "source": [
    "# print(y_pred)\n",
    "# print(y_test)\n",
    "y_pred2 = 1 / (1 + np.exp(-y_pred))\n",
    "y_pred2 = np.where(y_pred2 > 0.635, 1, 0)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred2)\n",
    "print(f\"ROC AUC Score for split{i}:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba05250-0499-4d13-a071-4942f810bad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for split1: 0.9495134796500907\n",
      "ROC AUC Score for split2: 0.9521999719367563\n",
      "ROC AUC Score for split3: 0.9519114372815806\n",
      "ROC AUC Score for split4: 0.9514632105364548\n",
      "ROC AUC Score for split5: 0.9518100665715554\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    train = pd.read_csv(\"data/split_1/train.tsv\", sep='\\t', header=0, dtype=str)\n",
    "    train['review'] = train['review'].str.replace('<.*?>', ' ', regex=True)\n",
    "    \n",
    "    y_train = train[\"sentiment\"].astype(int)\n",
    "    dtm_train = vocabvectorizer.transform(train['review'])\n",
    "    \n",
    "    ridge.fit(dtm_train, y_train)\n",
    "    \n",
    "    test = pd.read_csv(f\"data/split_{i}/test.tsv\", sep='\\t', header=0, dtype=str)\n",
    "    test['review'] = test['review'].str.replace('<.*?>', ' ', regex=True)\n",
    "    \n",
    "    y_test = pd.read_csv(f\"data/split_{i}/test_y.tsv\", sep='\\t', header=0, dtype=int)\n",
    "    y_test = y_test[\"sentiment\"].astype(int)\n",
    "    dtm_test = vocabvectorizer.transform(test['review'])\n",
    "\n",
    "    y_pred = ridge.predict(dtm_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"ROC AUC Score for split{i}:\", auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
