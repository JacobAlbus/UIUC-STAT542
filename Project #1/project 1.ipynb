{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe6a46d2-7ab5-40c7-a717-56b679ca576e",
   "metadata": {},
   "source": [
    "### Create plots of features vs sale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "771c3630-92f8-4078-9ece-032e59843476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data/fold1/train.csv\").fillna('None')\n",
    "data[\"Garage_Yr_Blt\"] = data[\"Garage_Yr_Blt\"].replace(\"None\", 0)\n",
    "data[\"Sale_Price\"] = np.log(data[\"Sale_Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d6c4d843-7f30-41f4-8a93-949985feea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['One_Story_1946_and_Newer_All_Styles', 'Two_Story_1946_and_Newer',\n",
       "       'One_Story_PUD_1946_and_Newer', 'Split_Foyer',\n",
       "       'Two_Story_PUD_1946_and_Newer', 'Split_or_Multilevel',\n",
       "       'One_Story_1945_and_Older', 'Duplex_All_Styles_and_Ages',\n",
       "       'One_and_Half_Story_Finished_All_Ages',\n",
       "       'Two_Family_conversion_All_Styles_and_Ages',\n",
       "       'Two_Story_1945_and_Older',\n",
       "       'One_Story_with_Finished_Attic_All_Ages',\n",
       "       'PUD_Multilevel_Split_Level_Foyer', 'Two_and_Half_Story_All_Ages',\n",
       "       'One_and_Half_Story_Unfinished_All_Ages',\n",
       "       'One_and_Half_Story_PUD_All_Ages'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"MS_SubClass\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "300f5207-1b01-4013-b575-9b26a97ddf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y = data[\"Sale_Price\"]\n",
    "\n",
    "for feature in data.columns[1:]:\n",
    "    if isinstance(data[feature].iloc[0], str):\n",
    "        feature_values = data[feature].unique()\n",
    "        mean_sale_prices = []\n",
    "        for feature_value in feature_values:\n",
    "            sale_price = data[data[feature] == feature_value][\"Sale_Price\"]\n",
    "            mean_sale_prices.append(sale_price.mean())\n",
    "        plt.bar(feature_values, mean_sale_prices)\n",
    "    else:\n",
    "        plt.scatter(data[feature], Y)    \n",
    "\n",
    "    plt.savefig(f\"figures/{feature}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "09e8ead3-88c3-4b15-964c-f75395cf5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(data, train_columns=None):\n",
    "    # Some values in Mas_Vnr_Type and Misc_feature have a Nan float value instead of just a \"None\" string\n",
    "    data = data.fillna('None')\n",
    "    # Some homes don't have garages so replace their \"None\" string with 0\n",
    "    data[\"Garage_Yr_Blt\"] = data[\"Garage_Yr_Blt\"].replace(\"None\", 0)\n",
    "\n",
    "    try:\n",
    "        y = np.log(data[\"Sale_Price\"])\n",
    "    except KeyError:\n",
    "        y = None\n",
    "\n",
    "    # Select all features except Sales Price\n",
    "    best_features = list(data.columns)[:-1]\n",
    "    data = data[best_features]\n",
    "\n",
    "    # One hot encoding of nominal features\n",
    "    X = pd.get_dummies(data[best_features])\n",
    "\n",
    "    # Handle column mismatch from one hot encoding\n",
    "    if train_columns is not None:\n",
    "        missing_columns = set(train_columns) - set(X.columns)\n",
    "        for column in missing_columns:\n",
    "            X[column] = 0\n",
    "        # Ensure the order of column in the test set is in the same order than in train set\n",
    "        X = X[train_columns]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bcdeb7b2-b5b0-42e2-b0b4-3c3e3184312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def xgb_cross_validate(X, y, folds):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    fold_size = n // folds\n",
    "    \n",
    "    min_error = sys.maxsize\n",
    "    best_eta = -1\n",
    "    best_T = -1\n",
    "\n",
    "    for eta in np.arange(0.05, 0.5, 0.05):\n",
    "        for T in np.arange(5, 50, 5):\n",
    "            # print(eta, T)\n",
    "            average_error = 0\n",
    "            for i in range(folds):\n",
    "                start = i * fold_size\n",
    "                end = (i + 1) * fold_size\n",
    "                \n",
    "                X_holdout = X[start:end]\n",
    "                X_train = np.concatenate([X[end:], X[:start]])\n",
    "                y_holdout = y[start:end]\n",
    "                y_train = np.concatenate([y[end:],y[:start]])\n",
    "\n",
    "                clf = xgb.XGBRegressor(n_estimators=T, learning_rate=eta)\n",
    "                clf.fit(X_train, y_train)\n",
    "                yhat = np.log(clf.predict(X_holdout))\n",
    "                \n",
    "                error = np.mean((y_holdout - yhat)**2)**(0.5)\n",
    "                average_error = ((average_error * i) + error) / (i + 1)\n",
    "            \n",
    "            if average_error <= min_error:\n",
    "                min_error = average_error\n",
    "                best_eta = eta\n",
    "                best_T = T\n",
    "    \n",
    "    return best_eta, best_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bdb0c712-c260-49a5-a928-ba38d1a0c509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for fold_1: 0.11601596770438807 0.025 10000\n",
      "RMSE for fold_2: 0.12264511855081735 0.025 10000\n",
      "RMSE for fold_3: 0.11292518944991467 0.025 10000\n",
      "RMSE for fold_4: 0.11756599634604162 0.025 10000\n",
      "RMSE for fold_5: 0.11287049849523371 0.025 10000\n",
      "RMSE for fold_6: 0.12660726933712557 0.025 10000\n",
      "RMSE for fold_7: 0.13121609245120477 0.025 10000\n",
      "RMSE for fold_8: 0.12451253333074389 0.025 10000\n",
      "RMSE for fold_9: 0.13268282043378155 0.025 10000\n",
      "RMSE for fold_10: 0.12445116079288275 0.025 10000\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "for i in range(1, 11):\n",
    "    X_train, y_train = preprocess_features(pd.read_csv(f\"data/fold{i}/train.csv\"))\n",
    "    # print(X_train.shape)\n",
    "    # cv_eta, cv_T = xgb_cross_validate(X_train, y_train, folds=10)\n",
    "    cv_eta = 0.025\n",
    "    cv_T = 10000\n",
    "    \n",
    "    X_test, _ = preprocess_features(pd.read_csv(f\"data/fold{i}/test.csv\"), X_train.columns)\n",
    "    y_test = pd.read_csv(f\"data/fold{i}/test_y.csv\")[\"Sale_Price\"]\n",
    "    y_test = np.log(y_test)\n",
    "    \n",
    "    clf = xgb.XGBRegressor(n_estimators=cv_T, learning_rate=cv_eta, \n",
    "                           max_depth=6, subsample=0.5, tree_method=\"exact\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    yhat = clf.predict(X_test)\n",
    "    \n",
    "    residuals = np.mean((y_test - yhat)**2)**(0.5)\n",
    "    print(f\"RMSE for fold_{i}:\", residuals, cv_eta, cv_T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
